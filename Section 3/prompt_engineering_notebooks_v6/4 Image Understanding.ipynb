{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Understanding\n",
    "\n",
    "GPT-4o and GPT-4o mini can understand what they see in an image.\n",
    "\n",
    "GPT-4o and GPT-4o mini are advertised as _multimodal_ models. A true multimodal model should be able to take input and give ouput in multiple _modes_. A mode can be text, images, audio, or video. The OpenAI API currently only supports images as an alternative input to text. The API does not support image generation.\n",
    "\n",
    "The model will also refuse to identify people in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the openai package and set the API key. \n",
    "#I have my API key stored in an environment variable for this demo.\n",
    "#In prod, you might prefer to use a secret store.\n",
    "import openai\n",
    "import os\n",
    "import backoff\n",
    "\n",
    "openai.api_key  = os.getenv('MY_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the model with a URL to an image\n",
    "\n",
    "We either pass a URL to an image. Or we can pass an image to the model. The approaches to doing this are very different. Let's start with passing an image URL to the model.\n",
    "\n",
    "We will be using this picture from the internet to query the model. It's called _Sitta europaea wildlife 3_, by Paweł Kuźniar\n",
    "![A picture from the internet that we will be using](https://upload.wikimedia.org/wikipedia/commons/e/e1/Sitta_europaea_wildlife_3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying our query function\n",
    "\n",
    "We will be passing a complete messages list to our query function. So we'll first modify it to accept a messages list.\n",
    "\n",
    "I've also renamed it to *query_model_single_turn()* because it's not just a _language_ model anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are using the backoff package to handle the rate limit error\n",
    "## We wrap the openai.ChatCompletion.create() in our own function \n",
    "### and use the @backoff.on_exception() decorator.\n",
    "@backoff.on_exception(backoff.expo, openai.RateLimitError)\n",
    "def query_model_single_turn(prompt, model=\"gpt-4o-mini\", temperature=0, **kwargs):\n",
    "    \"\"\"\n",
    "    This function queries the openai ChatCompletion API, with exponential backoff.\n",
    "    \n",
    "    Args:\n",
    "        prompt(str or list): The prompt or a list of messages.\n",
    "        model(str): The type of model to use. The default is \"gpt-4o-mini\".\n",
    "        temperature(float): The temperature to use. The default is 0.\n",
    "        **kwargs: Additional keyword arguments to be passed to openai.ChatCompletion.create()\n",
    "    Returns:\n",
    "        An opanai ChatCompletion object.\n",
    "    \"\"\"\n",
    "    ##Set up the messages list\n",
    "    if isinstance(prompt, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    else:\n",
    "        messages = prompt\n",
    "    return openai.chat.completions.create(\n",
    "        model=model,    \n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What's happening here?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/e/e1/Sitta_europaea_wildlife_3.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the image, a bird is perched on a person's hand, picking up seeds. The person is likely feeding the bird, and the bird appears to be comfortable enough to eat directly from the hand. The background is blurred, focusing attention on the interaction between the bird and the person.\n"
     ]
    }
   ],
   "source": [
    "response = query_model_single_turn(messages, model=\"gpt-4o\")\n",
    "the_reply = response.choices[0].message.content\n",
    "print(the_reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading an image to the model\n",
    "\n",
    "Currently, we can't use the openai package to upload an image to the model. So we'll be using the REST API.\n",
    "\n",
    "We'll be using the image in images/black-friday.jpg\n",
    "![The image that we will be prompting the model with](images/black-friday.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo, KeyError)\n",
    "def upload_image_and_query_model_single_turn(prompt, path_to_image, api_key, model=\"gpt-4o-mini\", temperature=0):\n",
    "    \"\"\"\n",
    "    This function queries the model with a text prompt, and an image. \n",
    "    The image is uploaded from disk.\n",
    "    \n",
    "    Args:\n",
    "        prompt(str): The prompt\n",
    "        path_to_image(str): The path to the image\n",
    "        api_key(str): The OpenAI API key\n",
    "        model(str): The type of model to use. The default is \"gpt-4o-mini\".\n",
    "        temperature(float): The temperature to use. The default is 0.\n",
    "    Returns:\n",
    "        The string of the model's reply.\n",
    "    \"\"\"\n",
    "    #1. Read and encode the image\n",
    "    with open(path_to_image, \"rb\") as image_file:\n",
    "        the_encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    #2. Set up the messages list (only one message)\n",
    "    messages_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"data:image/jpeg;base64,{0}\".format(the_encoded_image)\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    #3. Repare the payload\n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": \"Bearer {0}\".format(api_key)\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages_list,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    #3. Make the API call\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    #4. Parse the output\n",
    "    response_dict = response.json()\n",
    "    #5. Return the text of the reply\n",
    "    ##If we have any problems here, then it will be caught by the @backoff decorator\n",
    "    response_text = response_dict[\"choices\"][0][\"message\"][\"content\"] \n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_prompt = \"\"\"\n",
    "We have scraped the image from the internet. Please give the following information. Explain everything step by step.\n",
    "1. Describe the image.\n",
    "2. Describe what kind of website it likely came from.\n",
    "3. Describe what it was most likely being used for.\n",
    "Stay focused on your goals. With great focus, we will achieve fantastic outcomes!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s a step-by-step breakdown based on the image you provided:\n",
      "\n",
      "### 1. Describe the Image\n",
      "The image features a young woman with long, dark hair, smiling and looking upwards. She is wearing a gray, short-sleeved top. Surrounding her are numerous red squares with the word \"SALE\" prominently displayed in white text. The background is white, which enhances the visibility of the red squares and the text \"BLACK FRIDAY\" in large, bold black letters at the center of the image.\n",
      "\n",
      "### 2. Describe What Kind of Website It Likely Came From\n",
      "This image likely originated from a retail or e-commerce website, particularly one that promotes sales events. It could also be from a marketing or advertising site focused on seasonal promotions. The emphasis on \"Black Friday\" suggests it is aimed at consumers looking for deals during this major shopping event.\n",
      "\n",
      "### 3. Describe What It Was Most Likely Being Used For\n",
      "The image was most likely used for promotional purposes, such as an advertisement or a banner to attract customers to a Black Friday sale. It aims to convey excitement and urgency about the discounts available, encouraging viewers to participate in the shopping event. The cheerful expression of the woman adds a positive emotional appeal, making the sale seem more inviting. \n",
      "\n",
      "This structured approach helps in understanding the context and purpose of the image effectively!\n"
     ]
    }
   ],
   "source": [
    "response = upload_image_and_query_model_single_turn(our_prompt, \"images/black-friday.jpg\", os.getenv('MY_API_KEY'))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; Slava Razbash and AI Upskill (aiupskill.io)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (openai)",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
