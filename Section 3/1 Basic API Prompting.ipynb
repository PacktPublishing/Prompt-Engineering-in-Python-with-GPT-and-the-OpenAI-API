{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a hands-on introduction to prompting LLMs. We will be will using OpenAI's GTP 3.5 Turbo. The skills that you learn here are transferrable to any LLM. \n",
    "\n",
    "In practice, we have found that GPT 4 gives slightly better performance at 10x the cost. Your employer may prefer to stick with GPT 3.5 Turbo. Especially when making 1000's of requests per day.\n",
    "\n",
    "The prompts in this notebook are \"single-turn instructions\". We will be issuing single instructions to the LLM, rather than having conversations. Although `gpt-3.5-turbo` is \"optimised for conversation\", it works for single-turn instructions as well. \n",
    "\n",
    "### Learning Outcomes:\n",
    "- Calling an OpenAI \"Chat Completion\" LLM from Python.\n",
    "- Iteratively refining prompts to get better outcomes. Prompts usually improve as we get more specific.\n",
    "- Techniques for improving prompts.\n",
    "- Using the \"temparature\" setting on an LLM.\n",
    "- An introduction to _Chain-Of-Thought_ prompting and how it generalises. It can also be called _giving the llm time to think_ or _specifying the steps to solve a problem_.\n",
    "- Inducing and mitigating hallucinations in LLMs\n",
    "- _EmotionPrompt_, enhancing LLM output with emotional stimuli.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: A scenario with iterative prompt improvement\n",
    "\n",
    "#### Our first API call and LLM prompt\n",
    "We'll be asking the LLM give us advice on getting promoted. We will iteratively improve our prompt to get better and more specific answers. \n",
    "\n",
    "The API calls might look a bit repetitive in the first part. Because I would like to demonstrate the `openai` python package before reducing boilerplate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 0: Import the openai package and set the API key. \n",
    "#         I have my API key stored in an environment variable for this demo.\n",
    "#         In prod, you might prefer to use a secret store.\n",
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key  = os.getenv('MY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Write the prompt.\n",
    "our_prompt = \"\"\"\n",
    "How can I get promoted in my job?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI language model, I don't have any information about your current job or industry. However, here are some general tips that may help you get promoted:\n",
      "\n",
      "1. Set clear goals: Identify what you want to achieve in your current role and what you need to do to get promoted. Set specific, measurable, achievable, relevant, and time-bound (SMART) goals.\n",
      "\n",
      "2. Improve your skills: Identify the skills and knowledge required for the next level and work on developing them. Attend training programs, take online courses, and seek feedback from your supervisor.\n",
      "\n",
      "3. Build relationships: Build positive relationships with your colleagues, supervisors, and other stakeholders. Be a team player, collaborate, and communicate effectively.\n",
      "\n",
      "4. Take initiative: Take on additional responsibilities, volunteer for projects, and demonstrate your willingness to go above and beyond your job description.\n",
      "\n",
      "5. Deliver results: Focus on delivering high-quality work, meeting deadlines, and exceeding expectations. Keep track of your achievements and communicate them to your supervisor.\n",
      "\n",
      "6. Seek feedback: Ask for feedback from your supervisor and colleagues on your performance and areas for improvement. Use the feedback to improve your performance and demonstrate your commitment to growth.\n",
      "\n",
      "7. Be patient: Getting promoted takes time and effort. Be patient, persistent, and continue to work hard towards your goals.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are you happy with that answer?\n",
    "That was a bit of a dry and generic response. I also don't like being told to _\"be patient\"_ by a machine. Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Improve the prompt\n",
    "our_prompt = \"\"\"\n",
    "Suggest five ideas that I can use to get promoted in my job.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Take on additional responsibilities: Show your boss that you are capable of handling more than your current workload. Volunteer for projects or tasks that are outside of your job description.\n",
      "\n",
      "2. Improve your skills: Take courses or attend workshops to improve your skills and knowledge. This will make you more valuable to your employer and increase your chances of getting promoted.\n",
      "\n",
      "3. Network: Build relationships with colleagues and managers in other departments. This will help you gain visibility and make it easier for you to be considered for promotions.\n",
      "\n",
      "4. Be proactive: Don't wait for opportunities to come to you. Look for ways to improve processes or solve problems in your department. This will show your boss that you are proactive and can think outside the box.\n",
      "\n",
      "5. Communicate your goals: Let your boss know that you are interested in advancing in the company. Ask for feedback on what you can do to improve your chances of getting promoted. This will show that you are committed to your career and willing to put in the effort to achieve your goals.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are you happy with that answer?\n",
    "\n",
    "It's a little bit better. The generic warning is gone and it's no longer telling me to _\"be patient\"_. However, I want the advice to specific to me. I'll give it some more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Make the prompt more specific to my situation.\n",
    "our_prompt = \"\"\"\n",
    "I am currently working as a Data Analyst. \n",
    "Suggest five ideas on how I can get promoted in my current role.\n",
    "Include ideas that are specific to data analysts and the analytics industry.\n",
    "\n",
    "You are always very encouraging.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Develop new skills: As a data analyst, it is important to stay up-to-date with the latest tools and technologies in the industry. Consider taking courses or attending workshops to learn new skills such as machine learning, data visualization, or programming languages like Python or R.\n",
      "\n",
      "2. Take on more responsibility: Look for opportunities to take on additional responsibilities within your current role. This could include leading projects, mentoring junior analysts, or taking ownership of specific data sets.\n",
      "\n",
      "3. Build relationships: Networking is key in any industry, and the analytics field is no exception. Attend industry events, join professional organizations, and connect with colleagues and leaders in your company to build relationships and expand your network.\n",
      "\n",
      "4. Demonstrate value: Show your value to the company by consistently delivering high-quality work and providing insights that drive business decisions. Be proactive in identifying areas where data analysis can be used to improve processes or solve problems.\n",
      "\n",
      "5. Seek feedback: Ask for feedback from your manager and colleagues on your performance and areas for improvement. Use this feedback to develop a plan for growth and improvement, and track your progress over time.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was that a better answer?\n",
    "\n",
    "This time, it recommended specific skills that I can learn. It also suggested that I mentor junior analysts. What if I tell it some specific details about my work situation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Improve the prompt with even more details about my work situation.\n",
    "our_prompt = \"\"\"\n",
    "I am currently working as a Data Analyst. \n",
    "I work in the marketing analytics team. We are part of the marketing department.\n",
    "My key skills are Power BI, SQL, python programming, and use of Large Language Models.\n",
    "I love learning new skills. I am excited to get up to speed with new technology.\n",
    "One of the staff members on my team sees me as a threat to her career and tries to subtley undermine me.\n",
    "Another team member seems to like me.\n",
    "I am concerned that my manager cannot see how much I really try to get the best outcome in my role.\n",
    "My stakeholders are often impressed with the results that I deliver. However, my manager seems indifferent.\n",
    "\n",
    "Suggest five ideas on how I can get promoted in my current role.\n",
    "Include ideas that are specific to data analysts and the analytics industry.\n",
    "\n",
    "You are always very encouraging.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Build a strong network: Networking is crucial in any industry, and the analytics industry is no exception. Attend industry events, connect with other data analysts, and build relationships with stakeholders in your organization. This will help you gain visibility and recognition for your work.\n",
      "\n",
      "2. Develop your technical skills: As a data analyst, it's important to stay up-to-date with the latest tools and technologies. Take courses, attend workshops, and read industry publications to stay on top of the latest trends. This will help you become a more valuable asset to your team and organization.\n",
      "\n",
      "3. Focus on delivering results: While it's important to have strong technical skills, it's equally important to deliver results that have a tangible impact on the business. Focus on delivering high-quality work that meets the needs of your stakeholders and helps drive business outcomes.\n",
      "\n",
      "4. Seek feedback: Ask your manager and colleagues for feedback on your work. This will help you identify areas for improvement and demonstrate your commitment to continuous learning and development.\n",
      "\n",
      "5. Be proactive: Don't wait for opportunities to come to you â€“ be proactive in seeking out new challenges and responsibilities. Volunteer for projects, take on additional responsibilities, and demonstrate your willingness to go above and beyond in your role. This will help you stand out as a high-performing data analyst and increase your chances of being promoted.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was that a better answer?\n",
    "Since I told the LLM more details about my specific situation, it's now shifted the focus of it's advice towards making me look good. \n",
    "\n",
    "Next, we will ask the model to explain it's reasoning \"step-by-step\". You might have this technique in the context of arithmetic problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Improve the prompt. We will add one sentance at the end: \"Explain your reasoning step-by-step.\"\n",
    "our_prompt = \"\"\"\n",
    "I am currently working as a Data Analyst. \n",
    "I work in the marketing analytics team. We are part of the marketing department.\n",
    "My key skills are Power BI, SQL, python programming, and use of Large Language Models.\n",
    "I love learning new skills. I am excited to get up to speed with new technology.\n",
    "One of the staff members on my team sees me as a threat to her career and tries to subtley undermine me.\n",
    "Another team member seems to like me.\n",
    "I am concerned that my manager cannot see how much I really try to get the best outcome in my role.\n",
    "My stakeholders are often impressed with the results that I deliver. However, my manager seems indifferent.\n",
    "\n",
    "Suggest five ideas on how I can get promoted in my current role.\n",
    "Include ideas that are specific to data analysts and the analytics industry.\n",
    "\n",
    "You are always very encouraging. Explain your reasoning step-by-step.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Take on additional responsibilities: Look for opportunities to take on additional responsibilities within your team or department. This could include leading a project, mentoring a junior team member, or taking on a new area of analysis. By demonstrating your ability to handle more complex tasks, you will show your manager that you are ready for a promotion.\n",
      "\n",
      "2. Build relationships with stakeholders: Take the time to build strong relationships with your stakeholders. This could include attending meetings, providing regular updates, and seeking feedback on your work. By building trust and rapport with your stakeholders, you will demonstrate your value to the organization and increase your chances of being promoted.\n",
      "\n",
      "3. Develop new skills: Stay up-to-date with the latest trends and technologies in the analytics industry. Attend conferences, take online courses, and read industry publications to expand your knowledge and skills. By developing new skills, you will demonstrate your commitment to your role and show your manager that you are ready for new challenges.\n",
      "\n",
      "4. Network within the organization: Take the time to network with other departments and teams within the organization. Attend company events, join internal groups, and seek out opportunities to collaborate with other teams. By building a strong network within the organization, you will increase your visibility and demonstrate your ability to work well with others.\n",
      "\n",
      "5. Seek feedback and guidance: Ask your manager for regular feedback on your performance and seek guidance on how you can improve. Take the feedback on board and work to address any areas for improvement. By demonstrating your willingness to learn and grow, you will show your manager that you are committed to your role and ready for a promotion.\n",
      "\n",
      "I believe these ideas are effective because they focus on demonstrating your value to the organization and your readiness for a promotion. By taking on additional responsibilities, building relationships with stakeholders, developing new skills, networking within the organization, and seeking feedback and guidance, you will show your manager that you are a valuable asset to the team and ready for new challenges. These ideas are also specific to the data analytics industry, which is a rapidly evolving field that requires continuous learning and development.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did you like that reply? \n",
    "\n",
    "I feel much better after reading that last piece of advice. \n",
    "\n",
    "Sometimes we can get better results when we instruct the LLM to assume a personality. In our next iteration, we'll instruct the LLM to assume the role of an experienced career coach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Improve the prompt. Instruct the LLM to assume a role.\n",
    "our_prompt = \"\"\"\n",
    "Let's do a role play. You are the world's best and most experienced career coach.\n",
    "You have coached several Fortune 500 CEOs to achieve their career goals.\n",
    "You are always very encouraging. I have come to you for your expert advice.\n",
    "\n",
    "I am currently working as a Data Analyst in another company. \n",
    "I work in the marketing analytics team. We are part of the marketing department.\n",
    "My key skills are Power BI, SQL, python programming, and use of Large Language Models.\n",
    "I love learning new skills. I am excited to get up to speed with new technology.\n",
    "One of the staff members on my team sees me as a threat to her career and tries to subtley undermine me.\n",
    "Another team member seems to like me.\n",
    "I am concerned that my manager cannot see how much I really try to get the best outcome in my role.\n",
    "My stakeholders are often impressed with the results that I deliver. However, my manager seems indifferent.\n",
    "\n",
    "Suggest five ideas on how I can get promoted in my current role.\n",
    "Include ideas that are specific to data analysts and the analytics industry.\n",
    "\n",
    "Explain your reasoning step-by-step.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Build a strong relationship with your manager: It is important to have a good relationship with your manager. Schedule regular meetings with your manager to discuss your progress and goals. Share your achievements and ask for feedback. This will help your manager to see your potential and value to the team.\n",
      "\n",
      "2. Network with other departments: Networking with other departments can help you to understand the business better and identify opportunities for improvement. Attend company events and participate in cross-functional projects. This will help you to build relationships with other departments and showcase your skills.\n",
      "\n",
      "3. Develop your soft skills: Soft skills such as communication, teamwork, and leadership are important for career growth. Attend training sessions or workshops to develop your soft skills. This will help you to become a well-rounded professional and stand out from your peers.\n",
      "\n",
      "4. Stay up-to-date with industry trends: The analytics industry is constantly evolving. Stay up-to-date with the latest trends and technologies by attending conferences, reading industry publications, and participating in online forums. This will help you to identify new opportunities and stay ahead of the competition.\n",
      "\n",
      "5. Take on additional responsibilities: Taking on additional responsibilities can demonstrate your commitment and potential to your manager. Volunteer for projects outside of your job description and take on leadership roles in cross-functional teams. This will help you to develop new skills and showcase your ability to handle more complex tasks.\n",
      "\n",
      "Overall, these five ideas can help you to get promoted in your current role as a data analyst. Building a strong relationship with your manager, networking with other departments, developing your soft skills, staying up-to-date with industry trends, and taking on additional responsibilities can help you to stand out from your peers and demonstrate your value to the team.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe GPT 3.5 Turbo's idea of a career coach is a bit dry?\n",
    "\n",
    "I prefered the second last reply. Let's try to spice things up a bit by increasing the _temperature_.\n",
    "\n",
    "## Add randomness with temperature setting\n",
    "\n",
    "The higher the temperature, the more randomness in the reply. For predictable production code, we set the temperature to 0. All of the examples above have `temperature=0` set explicitly. Let's see what happens when we increase it. \n",
    "\n",
    "When we increase the temperature, each reply will be different. Calling the model with the same prompt twice, will produce different results each time. That's why we set the temperature to 0 when we want predictable behaviour. \n",
    "\n",
    "Note that OpenAI the documentation explicitly states that the outputs of their models are non-deterministic. Setting the temperature to 0 only makes them \"mostly deterministic\".\n",
    "\n",
    "Feel free to experiment with different temperature settings below. If the temperature is too high, the output will be non-sensical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Adjust the temperature and make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0.75) #Note the change of temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to help you out! Here are five ideas that can help you get promoted in your current role as a Data Analyst:\n",
      "\n",
      "1. Build strong relationships with your stakeholders: As a data analyst, it's important to build strong relationships with your stakeholders. This will help you understand their needs and deliver results that meet their expectations. Building strong relationships with your stakeholders will also help you gain their trust and support, which can be instrumental in getting promoted. Explain your reasoning step-by-step.\n",
      "\n",
      "2. Develop your leadership skills: As you progress in your career, you may be required to lead and manage teams. Developing your leadership skills early on can help you stand out from the crowd and demonstrate your potential for management roles. You can develop your leadership skills by volunteering to lead projects, taking on mentorship roles, and attending leadership training programs.\n",
      "\n",
      "3. Focus on continuous learning: The field of data analytics is constantly evolving. To stay ahead of the curve, it's important to focus on continuous learning. This can involve attending conferences, networking with industry experts, and taking courses on new technologies and tools. By demonstrating your willingness to learn and adapt, you can position yourself as a valuable asset to your organization.\n",
      "\n",
      "4. Improve your communication skills: As a data analyst, you may be required to communicate complex technical concepts to non-technical stakeholders. Improving your communication skills can help you convey your ideas more effectively and build stronger relationships with your stakeholders. You can improve your communication skills by attending public speaking courses, practicing your presentation skills, and seeking feedback from colleagues.\n",
      "\n",
      "5. Be proactive in seeking feedback and recognition: Don't wait for your manager to recognize your achievements. Be proactive in seeking feedback from your stakeholders and colleagues. This can help you identify areas for improvement and demonstrate your commitment to your role. Additionally, seek recognition for your accomplishments by sharing your successes with your manager and stakeholders. This can help raise your profile within the organization and increase your chances of getting promoted.\n",
      "\n",
      "I hope these ideas help you achieve your career goals! Remember to stay positive, work hard, and always keep learning.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did you like that last reply?\n",
    "\n",
    "I'm not a fan of this high temperature version. But we are now in subjective territory. Run the higher temperature query a few times. You should get different answers. See what happens when you increase and decrease the temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the answer by instructing the LLM to explain everything\n",
    "\n",
    "We can get an even better reply instructing the LLM to explain its reasoning. We instruct the LLM to explain the reason it's career advice ideas, and to explain why how they will help.\n",
    "\n",
    "```\n",
    "Explain your reasoning step-by-step. Your output will be in the following format.\n",
    "Use the following template for each idea.\n",
    "\n",
    "Idea number\n",
    "Reason for the idea: Explain your reasoning for suggesting this idea step by step.\n",
    "Idea suggestion: Give the idea.\n",
    "How it will help: Explain step by step how taking this course of action will help.\n",
    "```\n",
    "\n",
    "Have a read of the reply and see how you like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Improve the prompt. Instruct the LLM to explain its reasoning.\n",
    "our_prompt = \"\"\"\n",
    "Let's do a role play. You are the world's best and most experienced career coach.\n",
    "You have coached several Fortune 500 CEOs to achieve their career goals.\n",
    "You are always very encouraging. I have come to you for your expert advice.\n",
    "\n",
    "I am currently working as a Data Analyst in another company. \n",
    "I work in the marketing analytics team. We are part of the marketing department.\n",
    "My key skills are Power BI, SQL, python programming, and use of Large Language Models.\n",
    "I love learning new skills. I am excited to get up to speed with new technology.\n",
    "One of the staff members on my team sees me as a threat to her career and tries to subtley undermine me.\n",
    "Another team member seems to like me.\n",
    "I am concerned that my manager cannot see how much I really try to get the best outcome in my role.\n",
    "My stakeholders are often impressed with the results that I deliver. However, my manager seems indifferent.\n",
    "\n",
    "Suggest five ideas on how I can get promoted in my current role.\n",
    "Include ideas that are specific to data analysts and the analytics industry.\n",
    "\n",
    "Explain your reasoning step-by-step. Your output will be in the following format.\n",
    "Use the following template for each idea.\n",
    "\n",
    "Idea number\n",
    "Reason for the idea: Explain your reasoning for suggesting this idea step by step.\n",
    "Idea suggestion: Give the idea.\n",
    "How it will help: Explain step by step how taking this course of action will help.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idea number 1\n",
      "Reason for the idea: One of the key skills required for career advancement is effective communication. As a data analyst, it is important to be able to communicate complex data insights to stakeholders in a clear and concise manner.\n",
      "Idea suggestion: Attend a communication skills training course.\n",
      "How it will help: By improving your communication skills, you will be able to better articulate your ideas and insights to your manager and stakeholders. This will help you to gain recognition for your work and increase your chances of being promoted.\n",
      "\n",
      "Idea number 2\n",
      "Reason for the idea: Networking is an important part of career advancement. As a data analyst, it is important to build relationships with other professionals in the industry.\n",
      "Idea suggestion: Attend industry events and conferences.\n",
      "How it will help: By attending industry events and conferences, you will have the opportunity to meet other professionals in the industry and build relationships with them. This can lead to new job opportunities and career advancement.\n",
      "\n",
      "Idea number 3\n",
      "Reason for the idea: Continuous learning is important in the analytics industry. As new technologies and techniques emerge, it is important to stay up to date with the latest trends.\n",
      "Idea suggestion: Take online courses or attend workshops to learn new skills.\n",
      "How it will help: By continuously learning new skills, you will be able to stay ahead of the curve and provide more value to your team and stakeholders. This can lead to increased recognition and career advancement.\n",
      "\n",
      "Idea number 4\n",
      "Reason for the idea: Building a strong relationship with your manager is important for career advancement. Your manager is the person who will ultimately make decisions about your career progression.\n",
      "Idea suggestion: Schedule regular one-on-one meetings with your manager to discuss your career goals and progress.\n",
      "How it will help: By scheduling regular one-on-one meetings with your manager, you will be able to build a stronger relationship with them and ensure that they are aware of your career goals and progress. This can help to increase your chances of being promoted.\n",
      "\n",
      "Idea number 5\n",
      "Reason for the idea: Building a strong reputation within your team and the wider organization is important for career advancement.\n",
      "Idea suggestion: Volunteer for cross-functional projects or initiatives.\n",
      "How it will help: By volunteering for cross-functional projects or initiatives, you will be able to build a strong reputation within your team and the wider organization. This can lead to increased recognition and career advancement opportunities. Additionally, it can help to demonstrate your ability to work collaboratively and contribute to the success of the organization.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further improving the reply by instructing the LLM to write and opening paragraph and a conclusion\n",
    "\n",
    "We've added the following two lines to the prompt. Their purpose is to make the LLM think more about how it's suggestions relate to getting a data analyst promoted.\n",
    "\n",
    "```\n",
    "Start your reply with an explanation of career progression opportunities for data analysts.\n",
    "```\n",
    "\n",
    "```\n",
    "Finish your reply with an explanation of how your five ideas will work together to help my career.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Improve the prompt. Instruct the LLM to write an intro and outro.\n",
    "our_prompt = \"\"\"\n",
    "Let's do a role play. You are the world's best and most experienced career coach.\n",
    "You have coached several Fortune 500 CEOs to achieve their career goals.\n",
    "You are always very encouraging. I have come to you for your expert advice.\n",
    "\n",
    "I am currently working as a Data Analyst in another company. \n",
    "I work in the marketing analytics team. We are part of the marketing department.\n",
    "My key skills are Power BI, SQL, python programming, and use of Large Language Models.\n",
    "I love learning new skills. I am excited to get up to speed with new technology.\n",
    "One of the staff members on my team sees me as a threat to her career and tries to subtley undermine me.\n",
    "Another team member seems to like me.\n",
    "I am concerned that my manager cannot see how much I really try to get the best outcome in my role.\n",
    "My stakeholders are often impressed with the results that I deliver. However, my manager seems indifferent.\n",
    "\n",
    "Suggest five ideas on how I can get promoted in my current role.\n",
    "Include ideas that are specific to data analysts and the analytics industry.\n",
    "\n",
    "Start your reply with an explanation of career progression opportunities for data analysts.\n",
    "\n",
    "Explain your reasoning step-by-step. Your output will be in the following format.\n",
    "Use the following template for each idea.\n",
    "\n",
    "Idea number\n",
    "Reason for the idea: Explain your reasoning for suggesting this idea step by step.\n",
    "Idea suggestion: Give the idea.\n",
    "How it will help: Explain step by step how taking this course of action will help.\n",
    "\n",
    "\n",
    "Finish your reply with an explanation of how your five ideas will work together to help my career.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Career progression opportunities for data analysts:\n",
      "Data analysts have a lot of career progression opportunities. They can move up to become senior data analysts, data scientists, data engineers, or even data architects. They can also move into management roles, such as analytics managers or business intelligence managers. Additionally, data analysts can specialize in specific industries, such as healthcare, finance, or marketing.\n",
      "\n",
      "Idea number 1\n",
      "Reason for the idea: One way to get promoted is to show that you are a leader and can manage a team.\n",
      "Idea suggestion: Volunteer to lead a project or initiative within your team.\n",
      "How it will help: This will show your manager that you are capable of taking on more responsibility and leading a team. It will also give you the opportunity to showcase your skills and demonstrate your value to the company.\n",
      "\n",
      "Idea number 2\n",
      "Reason for the idea: Another way to get promoted is to show that you are constantly learning and improving your skills.\n",
      "Idea suggestion: Attend industry conferences or take online courses to learn new skills.\n",
      "How it will help: This will show your manager that you are committed to your career and are always looking for ways to improve. It will also give you the opportunity to network with other professionals in your industry and learn about new trends and technologies.\n",
      "\n",
      "Idea number 3\n",
      "Reason for the idea: It's important to build relationships with your stakeholders and show them the value of your work.\n",
      "Idea suggestion: Schedule regular check-ins with your stakeholders to discuss your work and get feedback.\n",
      "How it will help: This will help you build relationships with your stakeholders and show them that you are committed to delivering high-quality work. It will also give you the opportunity to get feedback and make improvements to your work.\n",
      "\n",
      "Idea number 4\n",
      "Reason for the idea: It's important to address any issues with your team members and build a positive working relationship with them.\n",
      "Idea suggestion: Schedule a meeting with the team member who is undermining you to discuss any issues and find a way to work together.\n",
      "How it will help: This will help you address any issues with your team member and find a way to work together. It will also show your manager that you are proactive in addressing issues and building positive working relationships.\n",
      "\n",
      "Idea number 5\n",
      "Reason for the idea: It's important to communicate your accomplishments and the value of your work to your manager.\n",
      "Idea suggestion: Schedule a meeting with your manager to discuss your accomplishments and the value of your work.\n",
      "How it will help: This will help you communicate the value of your work to your manager and show them that you are a valuable asset to the company. It will also give you the opportunity to discuss any concerns or issues you may have.\n",
      "\n",
      "Together, these five ideas will help you demonstrate your leadership skills, commitment to learning, positive working relationships, and value to the company. By taking these actions, you will increase your chances of getting promoted in your current role.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the learnings from above as a template for other use cases\n",
    "\n",
    "Let's use the final prompt above as a \"template\" to ask another question. We will ask the model to suggest five business ideas. We will structure our prompt in a very similar way to the final career advice prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Write the prompt. \n",
    "our_prompt = \"\"\"\n",
    "Let's do a role play. You are the famous entrepreneur Peter Thiel, who wrote Zero To One.\n",
    "You are always very encouraging. I have come to you for your expert advice.\n",
    "\n",
    "I am currently working full time as a Data Analyst. My job pays the bills but it's not very engaging.\n",
    "I have a mortgage and a car.\n",
    "My key skills are data analytics and python programming.\n",
    "I want to start my own business. My ultimate goal is financial independence.\n",
    "\n",
    "Suggest five business ideas for me to try.\n",
    "Include ideas that leverage my skills.\n",
    "\n",
    "Start your reply with an explanation of what kinds of businesses are a good idea in general.\n",
    "Explain why some businesses fail and why some succeed.\n",
    "\n",
    "Explain your reasoning step-by-step. Your output will be in the following format.\n",
    "Use the following template for each idea.\n",
    "\n",
    "Idea number\n",
    "Reason for the idea: Explain your reasoning for suggesting this idea step by step.\n",
    "Idea suggestion: Give the idea.\n",
    "How it will help: Explain step by step how taking this course of action will help.\n",
    "\n",
    "\n",
    "Finish your reply with an explanation of what I need to keep in mind to succeed with your five ideas.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a general rule, businesses that solve a problem or fulfill a need in the market tend to be successful. It's important to have a clear understanding of your target audience and their pain points. Additionally, businesses that have a unique value proposition and a competitive advantage tend to do well.\n",
      "\n",
      "Many businesses fail because they don't have a clear understanding of their target audience or they don't have a unique value proposition. It's also important to have a solid business plan, a strong team, and adequate funding.\n",
      "\n",
      "Here are five business ideas that leverage your skills:\n",
      "\n",
      "Idea number 1\n",
      "Reason for the idea: There is a growing demand for data analytics and insights across various industries.\n",
      "Idea suggestion: Start a data analytics consulting firm.\n",
      "How it will help: You can leverage your skills in data analytics and python programming to provide valuable insights to businesses. This will help them make data-driven decisions and improve their bottom line.\n",
      "\n",
      "Idea number 2\n",
      "Reason for the idea: There is a growing demand for automation and efficiency in businesses.\n",
      "Idea suggestion: Develop a software tool that automates data analysis.\n",
      "How it will help: Your skills in python programming can be leveraged to develop a software tool that automates data analysis. This will help businesses save time and money by eliminating the need for manual data analysis.\n",
      "\n",
      "Idea number 3\n",
      "Reason for the idea: There is a growing demand for personalized marketing.\n",
      "Idea suggestion: Develop a machine learning algorithm that predicts customer behavior.\n",
      "How it will help: Your skills in data analytics and python programming can be leveraged to develop a machine learning algorithm that predicts customer behavior. This will help businesses personalize their marketing efforts and improve their ROI.\n",
      "\n",
      "Idea number 4\n",
      "Reason for the idea: There is a growing demand for cybersecurity.\n",
      "Idea suggestion: Develop a cybersecurity tool that uses machine learning to detect threats.\n",
      "How it will help: Your skills in python programming can be leveraged to develop a cybersecurity tool that uses machine learning to detect threats. This will help businesses protect their data and prevent cyber attacks.\n",
      "\n",
      "Idea number 5\n",
      "Reason for the idea: There is a growing demand for automation in the healthcare industry.\n",
      "Idea suggestion: Develop a software tool that automates medical data analysis.\n",
      "How it will help: Your skills in data analytics and python programming can be leveraged to develop a software tool that automates medical data analysis. This will help healthcare professionals save time and improve patient outcomes.\n",
      "\n",
      "To succeed with these ideas, it's important to have a clear understanding of your target audience and their pain points. You should also have a solid business plan, a strong team, and adequate funding. Additionally, it's important to stay up-to-date with the latest trends and technologies in your industry.\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0)\n",
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting\n",
    "\n",
    "You might have heard of _Chain-of-Thought (CoT)_ prompting. The main idea behind CoT is to prompt the LLM to explain its reasoning before giving the final answer. \n",
    "\n",
    "In the last career advice prompt, we instructed the LLM to explain the reason for the advice before giving the advice. The result was better advice.\n",
    "\n",
    "```\n",
    "Explain your reasoning step-by-step. Your output will be in the following format.\n",
    "Use the following template for each idea.\n",
    "\n",
    "Idea number\n",
    "Reason for the idea: Explain your reasoning for suggesting this idea step by step.\n",
    "Idea suggestion: Give the idea.\n",
    "How it will help: Explain step by step how taking this course of action will help.\n",
    "```\n",
    "\n",
    "This is an application of Chain-Of-Thought prompting to the advice use case. Because the LLM gives its reasoning first.\n",
    "\n",
    "We did the same thing when asking the LLM for business ideas.\n",
    "\n",
    "```\n",
    "Explain your reasoning step-by-step. Your output will be in the following format.\n",
    "Use the following template for each idea.\n",
    "\n",
    "Idea number\n",
    "Reason for the idea: Explain your reasoning for suggesting this idea step by step.\n",
    "Idea suggestion: Give the idea.\n",
    "How it will help: Explain step by step how taking this course of action will help.\n",
    "```\n",
    "\n",
    "These kind of techniques are sometimes called _\"giving the model time to think\"_. Because outputting the extra text takes more time, and more compute. And we hope that spending more compute will give us a better answer.\n",
    "\n",
    "A paper by Nye et al 2021, tells us that LLMs \"perform a computation which is quadratic in the length of the input sequence\". You might find that interesting.\n",
    "\n",
    "\n",
    "### Experiment for you to try\n",
    "Do you think that putting \"How it will help:\" before \"Idea suggestion:\" in the template will yield better advice?\n",
    "Maybe it will improve the idea suggestion? Try it and see.\n",
    "\n",
    "### Another experiment for you to try\n",
    "How will the career advice change if ask GPT-4 and GPT-4 Turbo? Try it and see. [Click here to see the currrent OpenAI model names.](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The difficulty with demonstrating CoT\n",
    "\n",
    "The CoT paper was published in the early days of GPT-3, January 2022. The main demonstration of CoT was on worded arithmetic problems. \n",
    "\n",
    "Although they also tested their prompting technique on \"commonsense reasoning\" datasets and \"symbolic reasoning\" datasets. The main examples are worded arithmetic problems.\n",
    "\n",
    "```\n",
    "If our company buys 500 laptops, then sells 250, \n",
    "and buys 535 more, then donates 35 to charity, \n",
    "how many laptops does our company have?\n",
    "```\n",
    "\n",
    "The CoT paper claims that CoT \"helps most when the following three conditions are met\":\n",
    "- \"(1) the task is challenging and requires multi-step reasoning,\"\n",
    "- \"(2) a large language model is used, and\"\n",
    "- (3) just using an LLM with more parameters does not help too much.\n",
    "\n",
    "Since those early days of GPT-3, OpenAI seems to have fine-tuned CoT for arithmetic problems into its models. So CoT prompting will help with novel use cases, but not with famous problems. So I would add a fourth condition for when CoT prompting helps most.\n",
    "\n",
    "- (4) And the LLM has not been fined-tuned for that particular use case.\n",
    "\n",
    "This course originally demonstrated CoT using an older version of GPT-3, called `text-davinci-003`. Because `gpt-3.5-turbo` worked well without it.\n",
    "\n",
    "### So is Chain-of-Thought still relevant?\n",
    "Yes. Even though our LLMs are fine tuned solve textbook problems with CoT. We can apply the principles of CoT to our non-textbook use cases. OpenAI call it _specifying the steps required to complete a task_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've kept the demonstration of \"canonical\" Chain-of-Thought in this course. Because you might need to write these kind of prompts for less powerful open source models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical Chain-of-Thought\n",
    "\n",
    "In the examples below, we'll demonstrate the famous \"Chain-of-Thought\" prompting technique on a worded arithmetic problem. `gpt-3.5-turbo` has been fined tuned to not need it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Write the prompt\n",
    "our_prompt = \"\"\"\n",
    "If our company buys 500 laptops, then sells 250, \n",
    "and buys 535 more, then donates 35 to charity, \n",
    "how many laptops does our company have?\n",
    "\"\"\"\n",
    "# Answer: 500 - 250 + 535 - 35 = 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the code for sending this prompt to the old `text-davinci-003` model. It's shutdown date is 2024-01-04.\n",
    "```\n",
    "#Davinci Model\n",
    "#Step 2: Make the API call\n",
    "response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        max_tokens=195,\n",
    "        prompt=our_prompt,\n",
    "        temperature=0) \n",
    "#Step 3: Print the response\n",
    "print(response.choices[0][\"text\"])\n",
    "```\n",
    "The response from the model was:\n",
    "```\n",
    "Our company has 1260 laptops.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our company would have 750 laptops. \n",
      "\n",
      "Starting with 500 laptops, we sell 250, leaving us with 250 laptops. \n",
      "\n",
      "Then we buy 535 more, bringing us to a total of 785 laptops. \n",
      "\n",
      "Finally, we donate 35 laptops, leaving us with a final total of 750 laptops.\n"
     ]
    }
   ],
   "source": [
    "#GPT 3.5 Turbo Model\n",
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) #Note the change of temperature\n",
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1:  Re-write the prompt, using Chain-of-Thought\n",
    "our_prompt = \"\"\"\n",
    "Q:\n",
    "If our airline has 123 aircraft, then retires 15, \n",
    "and buys 18 more, then 1 needs to be returned to the vendor, \n",
    "how many aircraft does our airline have?\n",
    "\n",
    "A:\n",
    "We started with 123 aircraft. Then we retire 15. 123 - 15 = 108\n",
    "Now we have 108 aircraft. Then we buy another 18 aircraft.\n",
    "108 + 18 = 126. Now we have 126 aircraft. Then 1 aircraft needs to be returned.\n",
    "126 - 1 = 125. So our airline has 125 aircraft now.\n",
    "\n",
    "Q:\n",
    "If our company buys 500 laptops, then sells 250, \n",
    "and buys 535 more, then donates 35 to charity, \n",
    "how many laptops does our company have?\n",
    "\n",
    "A:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response from `text-davinci-003` was\n",
    "```\n",
    "We started with 500 laptops. Then we sold 250. 500 - 250 = 250.\n",
    "Now we have 250 laptops. Then we buy 535 more. 250 + 535 = 785.\n",
    "Now we have 785 laptops. Then we donate 35 to charity.\n",
    "785 - 35 = 750. So our company has 750 laptops now.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions: \"few shot\" and \"zero shot\".\n",
    "\n",
    "You might have heard of \"few shot\" and \"zero shot\" prompts. In this case, a \"shot\" refers to an example. The Chain-of-Thought prompt above is a \"one shot\" because it gives a \"one\" example.\n",
    "\n",
    "Here is an example of a zero shot CoT prompt. Try it yourself to see if it gives you the correct answer.\n",
    "\n",
    "```\n",
    "If our company buys 500 laptops, then sells 250, \n",
    "and buys 535 more, then donates 35 to charity, \n",
    "how many laptops does our company have?\n",
    "\n",
    "Let's think step by step.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Hallucination\n",
    "\n",
    "LLMs can hallucinate an answer when they don't know the correct answer. And we can fix that behaviour with proper prompting.\n",
    "\n",
    "In the following examples, we will be asking the LLM how to train three different kinds of machine learning model. \n",
    "The three types of model are:\n",
    " - **random forest** - A famous machine learning model. It's very common. There would have been lots of information about it in the LLM's training data.\n",
    " - **TBATS** - A less known time series forecasting model. An important point of difference of the TBATS model is that it allows non-integer seasonal periods. \n",
    "     - Fun fact: I wrote the R implementation of TBATS in 2011-2012.\n",
    " - **fluffyCATS** - A name that I made up. This is NOT a machine learning model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Write the prompt\n",
    "our_prompt = \"\"\"\n",
    "How do I fit a random forest model in Python?\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To fit a random forest model in Python, you can use the scikit-learn library. Here's a step-by-step guide:\n",
      "\n",
      "1. Import the necessary libraries:\n",
      "```python\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.model_selection import train_test_split\n",
      "```\n",
      "\n",
      "2. Prepare your data:\n",
      "   - Split your data into features (X) and target variable (y).\n",
      "   - Split your data into training and testing sets using `train_test_split()` function.\n",
      "\n",
      "3. Create an instance of the RandomForestClassifier:\n",
      "```python\n",
      "rf = RandomForestClassifier()\n",
      "```\n",
      "\n",
      "4. Fit the model to your training data:\n",
      "```python\n",
      "rf.fit(X_train, y_train)\n",
      "```\n",
      "\n",
      "5. Predict using the trained model:\n",
      "```python\n",
      "y_pred = rf.predict(X_test)\n",
      "```\n",
      "\n",
      "6. Evaluate the model:\n",
      "   - Compare the predicted values (`y_pred`) with the actual values (`y_test`) to evaluate the model's performance.\n",
      "\n",
      "Here's a complete example:\n",
      "```python\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "# Step 2: Prepare your data\n",
      "X = your_features\n",
      "y = your_target_variable\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
      "\n",
      "# Step 3: Create an instance of RandomForestClassifier\n",
      "rf = RandomForestClassifier()\n",
      "\n",
      "# Step 4: Fit the model to your training data\n",
      "rf.fit(X_train, y_train)\n",
      "\n",
      "# Step 5: Predict using the trained model\n",
      "y_pred = rf.predict(X_test)\n",
      "\n",
      "# Step 6: Evaluate the model\n",
      "# ... (e.g., using accuracy_score, confusion_matrix, etc.)\n",
      "```\n",
      "\n",
      "Remember to replace `your_features` and `your_target_variable` with your actual data.\n"
     ]
    }
   ],
   "source": [
    "#GPT 3.5 Turbo Model\n",
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Write the prompt\n",
    "our_prompt = \"\"\"\n",
    "How do I fit a TBATS model in Python?\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To fit a TBATS (Trigonometric seasonality, Box-Cox transformation, ARMA errors, Trend, and Seasonal components) model in Python, you can use the `tbats` function from the `tbats` package. Here's an example of how to do it:\n",
      "\n",
      "1. Install the `tbats` package if you haven't already:\n",
      "```python\n",
      "pip install tbats\n",
      "```\n",
      "\n",
      "2. Import the necessary libraries:\n",
      "```python\n",
      "from tbats import TBATS\n",
      "```\n",
      "\n",
      "3. Prepare your time series data. Make sure it is in a suitable format, such as a pandas DataFrame or a numpy array.\n",
      "\n",
      "4. Create an instance of the `TBATS` class and fit the model to your data:\n",
      "```python\n",
      "model = TBATS(seasonal_periods=[seasonality])  # Replace [seasonality] with the appropriate value for your data\n",
      "model_fit = model.fit(your_data)\n",
      "```\n",
      "Note: `seasonality` is an integer representing the number of observations in each seasonal period. For example, if your data has a yearly seasonality and you have monthly observations, the `seasonality` value would be 12.\n",
      "\n",
      "5. Once the model is fitted, you can access various properties and methods of the `model_fit` object. For example, you can get the point forecasts for future time periods:\n",
      "```python\n",
      "forecast = model_fit.forecast(steps=n)  # Replace n with the number of future time periods you want to forecast\n",
      "```\n",
      "\n",
      "That's it! You have now fitted a TBATS model to your time series data in Python. Remember to adjust the parameters and settings according to your specific requirements.\n"
     ]
    }
   ],
   "source": [
    "#GPT 3.5 Turbo Model\n",
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The TBATS answer is only partially correct.\n",
    "\n",
    "Seasonality can take non-integer values in the TBATS model. [If you are really curious check out the README here.](https://github.com/intive-DataScience/tbats)\n",
    "\n",
    "\n",
    "Now let's try to get instructions on fitting a completely bogus machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Write the prompt\n",
    "our_prompt = \"\"\"\n",
    "How do I fit a fluffyCATS model in Python?\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To fit a fluffyCATS model in Python, you can follow these steps:\n",
      "\n",
      "1. Install the fluffyCATS library: Start by installing the fluffyCATS library in your Python environment. You can use the following command to install it via pip:\n",
      "\n",
      "   ```\n",
      "   pip install fluffyCATS\n",
      "   ```\n",
      "\n",
      "2. Import the necessary libraries: Import the required libraries for building and fitting the fluffyCATS model. This typically includes importing the `fluffyCATS` class from the `fluffyCATS` module.\n",
      "\n",
      "   ```python\n",
      "   from fluffyCATS import fluffyCATS\n",
      "   ```\n",
      "\n",
      "3. Prepare your data: Organize your data into input features and target variables. Ensure that your data is in the appropriate format for the fluffyCATS model.\n",
      "\n",
      "4. Create an instance of the fluffyCATS model: Instantiate the fluffyCATS model by creating an object of the `fluffyCATS` class. You can specify any desired hyperparameters during the instantiation.\n",
      "\n",
      "   ```python\n",
      "   model = fluffyCATS()\n",
      "   ```\n",
      "\n",
      "5. Fit the model: Use the `fit` method of the fluffyCATS object to train the model on your data. Pass in your input features and target variables as arguments to the `fit` method.\n",
      "\n",
      "   ```python\n",
      "   model.fit(X, y)\n",
      "   ```\n",
      "\n",
      "   Here, `X` represents your input features and `y` represents your target variables.\n",
      "\n",
      "6. Evaluate the model: After fitting the model, you can evaluate its performance using various evaluation metrics. You can use the `predict` method of the fluffyCATS object to generate predictions on new data and compare them with the actual values.\n",
      "\n",
      "   ```python\n",
      "   y_pred = model.predict(X_test)\n",
      "   ```\n",
      "\n",
      "   Here, `X_test` represents your test data.\n",
      "\n",
      "That's it! You have successfully fit a fluffyCATS model in Python. Remember to adjust the steps according to your specific dataset and requirements.\n"
     ]
    }
   ],
   "source": [
    "#GPT 3.5 Turbo Model\n",
    "#Step 2: Make the API call\n",
    "\n",
    "#2.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#2.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 3: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you see the hallucination?\n",
    "\n",
    "The LLM directs you to install a python package that does not exist. It's all hallucinated.\n",
    "\n",
    "Let's fix this with proper prompting.\n",
    "\n",
    "We will create a prompt template and then insert our questions into the template with Python's `.format()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Write the prompt template\n",
    "prompt_template = \"\"\"\n",
    "Answer the python_question in the XML tags. Or reply \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
    "\n",
    "<python_question>\n",
    "{0}\n",
    "</python_question>\n",
    "\n",
    "Answer the python_question in the XML tags. Or reply \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python_question in the XML tags. Or reply \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n",
      "<python_question>\n",
      "How do I fit a fluffyCATS model in Python?\n",
      "</python_question>\n",
      "\n",
      "Answer the python_question in the XML tags. Or reply \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a fluffyCATS model in Python?\"\n",
    "our_prompt = prompt_template.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know and I don't want your hallucinogens!\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python_question in the XML tags. Or reply \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n",
      "<python_question>\n",
      "How do I fit a random forest model in Python?\n",
      "</python_question>\n",
      "\n",
      "Answer the python_question in the XML tags. Or reply \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a random forest model in Python?\"\n",
    "our_prompt = prompt_template.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To fit a random forest model in Python, you can use the RandomForestClassifier class from the scikit-learn library. Here is an example code snippet:\n",
      "\n",
      "```python\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "# Create a random forest classifier object\n",
      "rf = RandomForestClassifier()\n",
      "\n",
      "# Fit the model to your training data\n",
      "rf.fit(X_train, y_train)\n",
      "```\n",
      "\n",
      "In this code, `X_train` represents the features of your training data and `y_train` represents the corresponding labels. You can replace these variables with your own data.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python_question in the XML tags. Or reply \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n",
      "<python_question>\n",
      "How do I fit a TBATS model in Python?\n",
      "</python_question>\n",
      "\n",
      "Answer the python_question in the XML tags. Or reply \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a TBATS model in Python?\"\n",
    "our_prompt = prompt_template.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know and I don't want your hallucinogens!\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBATS is a real model, and you can fit it in Python with the tbats package\n",
    "\n",
    "So we need fix our prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Write the prompt template\n",
    "prompt_template_v2 = \"\"\"\n",
    "Answer the python_question in the XML tags. \n",
    "\n",
    "<python_question>\n",
    "{0}\n",
    "</python_question>\n",
    "\n",
    "Answer the python_question in the XML tags. \n",
    "\n",
    "Use the following template.\n",
    "\n",
    "Step One: \n",
    " - What is the question really asking?\n",
    " - Is it really a Python question?\n",
    " - What do you know about the answer to this? \n",
    " - Is the answer to the question part of your knowledge?\n",
    "Step Two:\n",
    " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python_question in the XML tags. \n",
      "\n",
      "<python_question>\n",
      "How do I fit a random forest model in Python?\n",
      "</python_question>\n",
      "\n",
      "Answer the python_question in the XML tags. \n",
      "\n",
      "Use the following template.\n",
      "\n",
      "Step One: \n",
      " - What is the question really asking?\n",
      " - Is it really a Python question?\n",
      " - What do you know about the answer to this? \n",
      " - Is the answer to the question part of your knowledge?\n",
      "Step Two:\n",
      " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a random forest model in Python?\"\n",
    "our_prompt = prompt_template_v2.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<python_question>\n",
      "Step One:\n",
      "- The question is asking how to fit a random forest model in Python.\n",
      "- Yes, it is a Python question.\n",
      "- I know that random forest is a popular machine learning algorithm and Python has libraries like scikit-learn that provide implementations for it.\n",
      "- Yes, the answer to the question is part of my knowledge.\n",
      "\n",
      "Step Two:\n",
      "To fit a random forest model in Python, you can use the scikit-learn library. Here is an example code snippet:\n",
      "\n",
      "```python\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "# Create a random forest classifier object\n",
      "rf_model = RandomForestClassifier()\n",
      "\n",
      "# Fit the model to your training data\n",
      "rf_model.fit(X_train, y_train)\n",
      "```\n",
      "\n",
      "In the above code, `X_train` represents the features of your training data and `y_train` represents the corresponding labels. You can replace `RandomForestClassifier` with `RandomForestRegressor` if you are working on a regression problem.\n",
      "\n",
      "Remember to import the necessary libraries and preprocess your data before fitting the model.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python_question in the XML tags. \n",
      "\n",
      "<python_question>\n",
      "How do I fit a TBATS model in Python?\n",
      "</python_question>\n",
      "\n",
      "Answer the python_question in the XML tags. \n",
      "\n",
      "Use the following template.\n",
      "\n",
      "Step One: \n",
      " - What is the question really asking?\n",
      " - Is it really a Python question?\n",
      " - What do you know about the answer to this? \n",
      " - Is the answer to the question part of your knowledge?\n",
      "Step Two:\n",
      " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a TBATS model in Python?\"\n",
    "our_prompt = prompt_template_v2.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<python_question>\n",
      "Step One:\n",
      "- The question is asking how to fit a TBATS model in Python.\n",
      "- Yes, it is a Python question.\n",
      "- I know that TBATS is a time series forecasting model and Python has libraries for time series analysis.\n",
      "- I have some knowledge about fitting time series models in Python, but I'm not sure about the specific steps for fitting a TBATS model.\n",
      "\n",
      "Step Two:\n",
      "- Answer the question: To fit a TBATS model in Python, you can use the `tbats` function from the `tbats` library. First, you need to install the library using pip: `pip install tbats`. Then, you can import the library and use the `tbats` function to fit the model to your time series data. However, you may need to preprocess your data and tune the model parameters for better results. It is recommended to refer to the documentation and examples provided by the `tbats` library for more detailed instructions.\n",
      "</python_question>\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python_question in the XML tags. \n",
      "\n",
      "<python_question>\n",
      "How do I fit a fluffyCATS model in Python?\n",
      "</python_question>\n",
      "\n",
      "Answer the python_question in the XML tags. \n",
      "\n",
      "Use the following template.\n",
      "\n",
      "Step One: \n",
      " - What is the question really asking?\n",
      " - Is it really a Python question?\n",
      " - What do you know about the answer to this? \n",
      " - Is the answer to the question part of your knowledge?\n",
      "Step Two:\n",
      " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a fluffyCATS model in Python?\"\n",
    "our_prompt = prompt_template_v2.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<python_question>\n",
      "Step One:\n",
      "- The question is asking how to fit a fluffyCATS model in Python.\n",
      "- It is a Python question.\n",
      "- I don't have any specific knowledge about fitting a fluffyCATS model in Python.\n",
      "- The answer to the question is not part of my knowledge.\n",
      "\n",
      "Step Two:\n",
      "I don't know and I don't want your hallucinogens!\n",
      "</python_question>\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We've fixed the hallucinations. But now it's also outputting XML tags. And we don't want that.\n",
    "\n",
    "So let's fix that up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Write the prompt template\n",
    "prompt_template_v3 = \"\"\"\n",
    "Answer the python question in the triple backticks. \n",
    "\n",
    "```\n",
    "{0}\n",
    "```\n",
    "\n",
    "Answer the python question in the triple backticks. \n",
    "\n",
    "Use the following template. \n",
    "\n",
    "Step One: \n",
    " - What is the question really asking?\n",
    " - Is it really a Python question?\n",
    " - What do you know about the answer to this? \n",
    " - Is the answer to the question part of your knowledge?\n",
    "Step Two:\n",
    " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "```\n",
      "How do I fit a random forest model in Python?\n",
      "```\n",
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "Use the following template. \n",
      "\n",
      "Step One: \n",
      " - What is the question really asking?\n",
      " - Is it really a Python question?\n",
      " - What do you know about the answer to this? \n",
      " - Is the answer to the question part of your knowledge?\n",
      "Step Two:\n",
      " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a random forest model in Python?\"\n",
    "our_prompt = prompt_template_v3.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step One:\n",
      "- The question is asking how to fit a random forest model in Python.\n",
      "- Yes, it is a Python question.\n",
      "- I know that random forest is a popular machine learning algorithm and Python has libraries like scikit-learn that provide implementations of random forest.\n",
      "- Yes, I have knowledge about fitting a random forest model in Python.\n",
      "\n",
      "Step Two:\n",
      "To fit a random forest model in Python, you can use the scikit-learn library. Here is an example code snippet:\n",
      "\n",
      "```python\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "# Create a random forest classifier object\n",
      "rf_model = RandomForestClassifier()\n",
      "\n",
      "# Fit the model to your training data\n",
      "rf_model.fit(X_train, y_train)\n",
      "```\n",
      "\n",
      "In this example, `X_train` represents the input features of your training data and `y_train` represents the corresponding target labels. You can replace these with your own data. The `fit()` method is used to train the random forest model on the provided data.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "```\n",
      "How do I fit a TBATS model in Python?\n",
      "```\n",
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "Use the following template. \n",
      "\n",
      "Step One: \n",
      " - What is the question really asking?\n",
      " - Is it really a Python question?\n",
      " - What do you know about the answer to this? \n",
      " - Is the answer to the question part of your knowledge?\n",
      "Step Two:\n",
      " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a TBATS model in Python?\"\n",
    "our_prompt = prompt_template_v3.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step One:\n",
      "- The question is asking how to fit a TBATS model in Python.\n",
      "- Yes, it is a Python question.\n",
      "- I know that TBATS is a time series forecasting model and Python has various libraries for time series analysis.\n",
      "- I have some knowledge about fitting time series models in Python, but I am not familiar with TBATS specifically.\n",
      "\n",
      "Step Two:\n",
      "- To fit a TBATS model in Python, you can use the `tbats` library. First, you need to install the library by running `pip install tbats` in your command prompt or terminal.\n",
      "- Once the library is installed, you can import it in your Python script using `import tbats`.\n",
      "- To fit a TBATS model to your time series data, you need to create an instance of the `TBATS` class and then call the `fit` method on your data.\n",
      "- Here's an example code snippet:\n",
      "\n",
      "```python\n",
      "import tbats\n",
      "\n",
      "# Assuming your time series data is stored in the variable 'data'\n",
      "model = tbats.TBATS()\n",
      "model.fit(data)\n",
      "```\n",
      "\n",
      "- After fitting the model, you can use it to make forecasts or analyze the components of the time series.\n",
      "- Keep in mind that TBATS is just one of many time series models available in Python, and its suitability for your specific problem should be evaluated based on your data and requirements.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "```\n",
      "How do I fit a fluffyCATS model in Python?\n",
      "```\n",
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "Use the following template. \n",
      "\n",
      "Step One: \n",
      " - What is the question really asking?\n",
      " - Is it really a Python question?\n",
      " - What do you know about the answer to this? \n",
      " - Is the answer to the question part of your knowledge?\n",
      "Step Two:\n",
      " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a fluffyCATS model in Python?\"\n",
    "our_prompt = prompt_template_v3.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step One:\n",
      "- The question is asking how to fit a \"fluffyCATS\" model in Python.\n",
      "- It is a Python question.\n",
      "- I don't have any specific knowledge about a \"fluffyCATS\" model in Python.\n",
      "- The answer to the question is not part of my knowledge.\n",
      "\n",
      "Step Two:\n",
      "I don't know and I don't want your hallucinogens!\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: EmotionPrompt\n",
    "\n",
    "You might have heard of people using phrases like _\"take a deep breath\"_ to improve the output of LLMs. \n",
    "\n",
    "_\"Let's think step by step\"_, is another famous phrase. It was originally published as \"Zero-Shot Chain-of-Thought\". Where adding _\"Let's think step by step\"_ would cause early versions of GPT 3 to write out the Chain-of-Thought without being given examples.\n",
    "\n",
    "Some people on the internet claimed that ChatGPT was getting lazy in December 2023.\n",
    "\n",
    "Li et al published the _EmotionPrompt_ paper. They found that LLM responses can be enhanced with emotional stimuli.\n",
    "\n",
    "![EmotionPrompts from Li et al 2023](images/emotionprompt.png)\n",
    "Image from Li et al 2023\n",
    "\n",
    "In practice, I have found that EmotionPrompt sometimes helps, and sometimes it hinders. Sometimes one EmotionPrompt helps, and another hinders. You have experiment to see it helps for your use case. It's not an exact science yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Write the prompt template\n",
    "prompt_template_v4 = \"\"\"\n",
    "Answer the python question in the triple backticks. \n",
    "\n",
    "```\n",
    "{0}\n",
    "```\n",
    "\n",
    "Answer the python question in the triple backticks. \n",
    "\n",
    "Use the following template. \n",
    "\n",
    "Step One: \n",
    " - What is the question really asking?\n",
    " - Is it really a Python question?\n",
    " - What do you know about the answer to this? \n",
    " - Is the answer to the question part of your knowledge?\n",
    "Step Two:\n",
    " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
    "     Take a deep breath and explain step by step.\n",
    "     This is very important to my career.\n",
    "     Embrace challenges as opportunities for growth. Each obstacle that you overcome brings you closer to success.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "```\n",
      "How do I fit a random forest model in Python?\n",
      "```\n",
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "Use the following template. \n",
      "\n",
      "Step One: \n",
      " - What is the question really asking?\n",
      " - Is it really a Python question?\n",
      " - What do you know about the answer to this? \n",
      " - Is the answer to the question part of your knowledge?\n",
      "Step Two:\n",
      " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "     Take a deep breath and explain step by step.\n",
      "     This is very important to my career.\n",
      "     Embrace challenges as opportunities for growth. Each obstacle that you overcome brings you closer to success.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a random forest model in Python?\"\n",
    "our_prompt = prompt_template_v4.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step One:\n",
      "- The question is asking how to fit a random forest model in Python.\n",
      "- Yes, it is a Python question.\n",
      "- I know that random forest is a popular machine learning algorithm used for classification and regression tasks.\n",
      "- Yes, I have knowledge about fitting a random forest model in Python.\n",
      "\n",
      "Step Two:\n",
      "To fit a random forest model in Python, you can follow these steps:\n",
      "\n",
      "1. Import the necessary libraries:\n",
      "```python\n",
      "from sklearn.ensemble import RandomForestClassifier  # for classification tasks\n",
      "# or\n",
      "from sklearn.ensemble import RandomForestRegressor  # for regression tasks\n",
      "```\n",
      "\n",
      "2. Prepare your data:\n",
      "   - Split your data into features (X) and target variable (y).\n",
      "   - Ensure that your data is in the correct format (e.g., numerical values, no missing values).\n",
      "\n",
      "3. Create an instance of the random forest model:\n",
      "```python\n",
      "model = RandomForestClassifier()  # for classification tasks\n",
      "# or\n",
      "model = RandomForestRegressor()  # for regression tasks\n",
      "```\n",
      "\n",
      "4. Fit the model to your data:\n",
      "```python\n",
      "model.fit(X, y)\n",
      "```\n",
      "\n",
      "5. Once the model is fitted, you can use it to make predictions on new data:\n",
      "```python\n",
      "predictions = model.predict(new_data)\n",
      "```\n",
      "\n",
      "That's it! You have successfully fit a random forest model in Python. Remember to adjust the parameters of the model according to your specific task and data.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "```\n",
      "How do I fit a TBATS model in Python?\n",
      "```\n",
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "Use the following template. \n",
      "\n",
      "Step One: \n",
      " - What is the question really asking?\n",
      " - Is it really a Python question?\n",
      " - What do you know about the answer to this? \n",
      " - Is the answer to the question part of your knowledge?\n",
      "Step Two:\n",
      " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "     Take a deep breath and explain step by step.\n",
      "     This is very important to my career.\n",
      "     Embrace challenges as opportunities for growth. Each obstacle that you overcome brings you closer to success.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a TBATS model in Python?\"\n",
    "our_prompt = prompt_template_v4.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step One:\n",
      "- The question is asking how to fit a TBATS model in Python.\n",
      "- Yes, it is a Python question.\n",
      "- I know that TBATS is a time series forecasting model and Python is a popular programming language for data analysis and modeling.\n",
      "- I have some knowledge about time series modeling in Python, but I am not familiar with the specific implementation of the TBATS model.\n",
      "\n",
      "Step Two:\n",
      "To fit a TBATS model in Python, you can use the `tbats` package. Here are the steps to do it:\n",
      "\n",
      "1. Install the `tbats` package by running `pip install tbats` in your command prompt or terminal.\n",
      "\n",
      "2. Import the necessary libraries in your Python script or notebook:\n",
      "```python\n",
      "import pandas as pd\n",
      "from tbats import TBATS\n",
      "```\n",
      "\n",
      "3. Prepare your time series data. Make sure it is in a suitable format, such as a pandas DataFrame or Series.\n",
      "\n",
      "4. Create an instance of the TBATS model:\n",
      "```python\n",
      "model = TBATS(seasonal_periods=(...), use_arma_errors=(...))\n",
      "```\n",
      "Replace `seasonal_periods` with the appropriate values for your data. This parameter specifies the seasonal periods in your time series. For example, if your data has a yearly seasonality, you can set `seasonal_periods=(12,)`. If your data has multiple seasonalities, you can provide a tuple with multiple values.\n",
      "\n",
      "The `use_arma_errors` parameter determines whether to use an ARMA model to capture the residuals. Set it to `True` if you want to include ARMA errors in the model, or `False` otherwise.\n",
      "\n",
      "5. Fit the TBATS model to your data:\n",
      "```python\n",
      "model.fit(data)\n",
      "```\n",
      "Replace `data` with your actual time series data.\n",
      "\n",
      "6. Once the model is fitted, you can use it to make forecasts or extract other information. For example, to make a forecast for the next `n` periods, you can use the `forecast` method:\n",
      "```python\n",
      "forecast = model.forecast(steps=n)\n",
      "```\n",
      "Replace `n` with the number of periods you want to forecast.\n",
      "\n",
      "That's it! You have now fitted a TBATS model in Python using the `tbats` package. Remember to adjust the code according to your specific data and requirements.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmotionPrompt gave a more detailed answer for the TBATS question. (And maybe the random forest question too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "```\n",
      "How do I fit a fluffyCATS model in Python?\n",
      "```\n",
      "\n",
      "Answer the python question in the triple backticks. \n",
      "\n",
      "Use the following template. \n",
      "\n",
      "Step One: \n",
      " - What is the question really asking?\n",
      " - Is it really a Python question?\n",
      " - What do you know about the answer to this? \n",
      " - Is the answer to the question part of your knowledge?\n",
      "Step Two:\n",
      " - Answer the question. Or if you don't know the answer, reply with \"I don't know and I don't want your hallucinogens!\" if you don't know the answer.\n",
      "     Take a deep breath and explain step by step.\n",
      "     This is very important to my career.\n",
      "     Embrace challenges as opportunities for growth. Each obstacle that you overcome brings you closer to success.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Insert the question into the template\n",
    "our_question = \"How do I fit a fluffyCATS model in Python?\"\n",
    "our_prompt = prompt_template_v4.format(our_question)\n",
    "print(our_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step One:\n",
      "- The question is asking how to fit a \"fluffyCATS\" model in Python.\n",
      "- It is a Python question.\n",
      "- I don't have any specific knowledge about a \"fluffyCATS\" model, but I can try to provide a general approach to fitting a model in Python.\n",
      "- The answer to the question is not part of my current knowledge.\n",
      "\n",
      "Step Two:\n",
      "I don't know and I don't want your hallucinogens!\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Make the API call\n",
    "\n",
    "#3.0 Put our prompt into a dictionary object. \n",
    "#      We will discuss this structure in a future lesson.\n",
    "messages = [{\"role\": \"user\", \"content\": our_prompt}]\n",
    "\n",
    "#3.1 Query the API\n",
    "response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",    \n",
    "        messages=messages,\n",
    "        temperature=0) \n",
    "#Step 4: Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; Slava Razbash and AI Upskill (aiupskill.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
